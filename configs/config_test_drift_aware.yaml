clock:
  frequency_code: 9
  frequency_type: second
clock_measurement:
  ntp:
    max_acceptable_uncertainty: 0.1
    max_stratum: 16
    measurement_mode: advanced
    min_stratum: 1
    servers:
    - pool.ntp.org
    - time.nist.gov
    - time.google.com
    timeout_seconds: 2.0
  timing:
    normal_operation:
      measurement_interval: 120  # 2 minutes (was 180s/3min) - faster learning
    warm_up:
      duration_seconds: 60
      measurement_interval: 1  # 1 second (was 5s) - more aggressive warmup
covariates:
  enabled: false
  future_variables: []
  variables:
  - cpu_usage
  - temperature
  - memory_usage
fusion:
  enabled: true
  fallback_weights:
    long_term: 0.2
    short_term: 0.8
  method: none
  uncertainty_threshold: 0.05
logging:
  level: INFO
  log_fusion_weights: true
  log_predictions: true
  log_uncertainty: true
long_term:
  context_length: 512
  device: cpu
  enabled: true
  inference_interval: 30.0
  max_uncertainty: 0.15
  model_name: timesfm
  model_params:
    backend: cpu
    context_length: 512
    model_repo: google/timesfm-2.5-200m-pytorch
    prediction_length: 60
  prediction_horizon: 60
performance:
  batch_size: 1
  cache_size: 5
  max_memory_mb: 2048
  model_timeout: 10.0
prediction_scheduling:
  cpu_model:
    max_inference_time: 2.0
    prediction_horizon: 30
    prediction_interval: 5
    prediction_lead_time: 5
  dataset:
    max_history_size: 1000
    prediction_cache_size: 100
  gpu_model:
    max_inference_time: 5.0
    prediction_horizon: 240
    prediction_interval: 30
    prediction_lead_time: 10
  ntp_correction:
    drift_uncertainty: 0.0001
    enabled: true
    method: backtracking
    offset_uncertainty: 0.001
  adaptive_capping:
    # LAYER 1: Ultra-Aggressive Capping (based on failure analysis)
    # Failure: Previous config allowed 2.3s predictions → catastrophic divergence
    # Fix: Cap at 2.5x last NTP with hard 300ms max
    max_multiplier: 2.5        # Cap to 2.5x last NTP magnitude (replaces drift calculation)
    absolute_max: 0.300        # Hard maximum: 300ms (prevent all catastrophic predictions)
    absolute_min: 0.001        # Minimum cap: 1ms (was 5ms) - allow convergence to ±3ms NTP truth
  sanity_check:
    # LAYER 2: Adaptive Sanity Check (learns from system clock behavior)
    # Predictions must be within observed NTP error ± (multiplier × NTP error)
    # Example: If avg NTP error = 10ms and multiplier = 2.0
    #   → Lower bound: 10ms - 20ms = max(1ms, -10ms) = 1ms
    #   → Upper bound: 10ms + 20ms = 30ms
    #   → Valid range: [1ms, 30ms]
    # This adapts to system characteristics (WSL2 vs normal clocks)
    enabled: true
    adaptive_range_multiplier: 10.0  # Predictions within avg_error ± (10 × avg_error)
    absolute_min_bound: 0.001         # Never allow predictions < 1ms (enforce sanity floor)
    absolute_max_bound: 10.0          # Never allow predictions > 10s (catastrophic failures)
    relative_limit: 5.0               # Fallback: Reject if > 5x average NTP magnitude
    statistical_limit: 3.0            # Fallback: Reject if > 3 sigma from NTP mean
  confidence_capping:
    # LAYER 3: DISABLED (caused confusion with dual-capping system)
    # Keeping config structure for compatibility but not used
    enabled: false
    high_confidence_threshold: 0.8
    medium_confidence_threshold: 0.5
    medium_confidence_multiplier: 1.5
    low_confidence_multiplier: 1.2
preprocessing:
  missing_value_handling:
    enabled: true
    method: interpolate
  normalization:
    enabled: false
    method: zscore
  outlier_removal:
    enabled: true
    method: iqr
    threshold: 2.0
short_term:
  context_length: 512
  device: cpu
  enabled: true
  inference_interval: 1.0
  max_uncertainty: 0.1
  model_name: timesfm
  model_params:
    backend: cpu
    context_length: 512
    model_repo: google/timesfm-2.5-200m-pytorch
    prediction_length: 30
  prediction_horizon: 30
